<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Assignment 1. Analysis of WizMap Scalable Interactive Visualization | The Only Problem's Blog</title><meta name=keywords content="可解释性,Embedding,可视化"><meta name=description content="本文就原论文分析了交互式可视化工具 WizMap，探讨其如何通过创新的多尺度摘要技术解决大规模机器学习嵌入的可视化和解释难题，并介绍了其用户界面、应用场景及未来发展。"><meta name=author content="The Only Problem"><link rel=canonical href=https://congyuxiaoyoudao.github.io/posts/assignments/analysis-of-wizmap-scalable-interactive-visualization/><link crossorigin=anonymous href=/assets/css/stylesheet.452758010f0b7fc9ad7fa528ffdfdd8eb9e830816fb8c8119f16f39583297db8.css integrity="sha256-RSdYAQ8Lf8mtf6Uo/9/djrnoMIFvuMgRnxbzlYMpfbg=" rel="preload stylesheet" as=style><link rel=icon href=https://congyuxiaoyoudao.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://congyuxiaoyoudao.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://congyuxiaoyoudao.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://congyuxiaoyoudao.github.io/apple-touch-icon.png><link rel=mask-icon href=https://congyuxiaoyoudao.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://congyuxiaoyoudao.github.io/posts/assignments/analysis-of-wizmap-scalable-interactive-visualization/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity=sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity=sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity=sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk crossorigin=anonymous onload='window.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\$$",right:"\\\\$$",display:!1},{left:"\\$$",right:"\\\\$$",display:!0}]})})'></script><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.bootcdn.net/ajax/libs/lxgw-wenkai-screen-webfont/1.7.0/style.min.css><meta property="og:url" content="https://congyuxiaoyoudao.github.io/posts/assignments/analysis-of-wizmap-scalable-interactive-visualization/"><meta property="og:site_name" content="The Only Problem's Blog"><meta property="og:title" content="Assignment 1. Analysis of WizMap Scalable Interactive Visualization"><meta property="og:description" content="本文就原论文分析了交互式可视化工具 WizMap，探讨其如何通过创新的多尺度摘要技术解决大规模机器学习嵌入的可视化和解释难题，并介绍了其用户界面、应用场景及未来发展。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-21T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-21T00:00:00+00:00"><meta property="article:tag" content="可解释性"><meta property="article:tag" content="Embedding"><meta property="article:tag" content="可视化"><meta name=twitter:card content="summary"><meta name=twitter:title content="Assignment 1. Analysis of WizMap Scalable Interactive Visualization"><meta name=twitter:description content="本文就原论文分析了交互式可视化工具 WizMap，探讨其如何通过创新的多尺度摘要技术解决大规模机器学习嵌入的可视化和解释难题，并介绍了其用户界面、应用场景及未来发展。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://congyuxiaoyoudao.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Assignments","item":"https://congyuxiaoyoudao.github.io/posts/assignments/"},{"@type":"ListItem","position":3,"name":"Assignment 1. Analysis of WizMap Scalable Interactive Visualization","item":"https://congyuxiaoyoudao.github.io/posts/assignments/analysis-of-wizmap-scalable-interactive-visualization/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Assignment 1. Analysis of WizMap Scalable Interactive Visualization","name":"Assignment 1. Analysis of WizMap Scalable Interactive Visualization","description":"本文就原论文分析了交互式可视化工具 WizMap，探讨其如何通过创新的多尺度摘要技术解决大规模机器学习嵌入的可视化和解释难题，并介绍了其用户界面、应用场景及未来发展。","keywords":["可解释性","Embedding","可视化"],"articleBody":" 由于嵌入式模型的不透明、高维度以及大规模现代数据集的限制，对其进行解释和使用极具挑战性。Zijie J. Wang 等开发了 WizMap，一个交互式可视化工具，允许用户轻松探索和解释嵌入式大模型\n🚩 0x00 To begin with 应可视化课程要求，本篇旨在对原论文项目进行粗浅的翻译\u0026介绍\u0026分析，仅作学习之用 论文名：WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings 作者：Zijie J. Wang, Fred Hohman, Duen Horng Chau\n这篇文章将会包含以下内容：\nEmbedding Model 及其局限 前人的交互可视化工具 散点图 等高线图 WizMap 的目的及意义 WizMap 的实现分析 笔者的看法 For reference👇：\n📖 原论文地址： [2306.09328] WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings 📺 原演示视频： Demo Video “WizMAP: Scalable Interactive Visualization for Exploring Large ML Embeddings” 🔧 演示地址： WizMap 📖 没有思考过 Embedding，不足以谈 AI 📺 Machine Learning Crash Course: Embeddings 📺 14 Embedding Projector 🤔 0x01 What is LLM Embedding 为了让没有接触过机器学习的读者更容易理解原论文的工作，笔者加上了此节\nConcept of Embedding 嵌入的概念 在数学上，Embedding 代表一个映射关系：$f:X\\to Y$，该关系是同构的，即在单射条件下保持数学结构（加性、乘法等）；在机器学习领域，用于将数据源映射到另外一个空间，数据源可以来自于文本、图像甚至视频，这里以文本为例\n对于人而言，语言有丰富的上下文、语法规则、多义性、文化背景等特性。而对于机器而言，语言只不过是 0 和 1 。如果想让机器能够“理解”自然语言，就需要对文本信息进行抽象编码。\nEmbedding（嵌入）就提供了对自然语言的一层抽象，将离散的文本输入转换为连续的向量表示。这种向量表示能够捕捉文本的语义（上下文）信息，使其可以被 LLM 处理、存储和计算。\nSemantic Baseed Encoding 基于词义的编码 Embedding 对自然语言到多维向量空间的映射必须是一一映射，也即每个词语映射到一个唯一向量，不同词语映射的向量不同。这种操作有效降低了因为自然语言中可能存在的“多词一义”、“一词多义”而导致的复杂性，也是编码需要遵循的条件之一。\n映射到多维向量空间主要有两个理由：\n1.可以对应单词多维度特征，也即单词不同层面的属性。相较于标量，向量能够承载更多的信息，Embedding 就像把这些属性“嵌入”到向量各维度的值的过程。比如说 apple 可以表示为这样：\nWord Animal Big Red Expensive … apple -0.5 0.1 0.7 0.3 … 属性只是举个例子，不太恰当敬请谅解\n然而如何确定能描述全部自然语言词语的所有维度是困难的。即使是同一词语，在不同上下文的意义也可能不同，与其大费周章找到一套固定的维度，不如将词语定义在其处于的上下文中，用词与词之间的关系定义词。\nApple pie is my favorite dessert during the holidays. Discover the innovative world of Apple and shop everything iPhone… 在第一句中，Apple 的含义与 Pear 接近，但在第二句中却与 Huawei 接近。\n2.可以对向量（准确而言是向量之间的关系）进行度量。这里就用到一些基本的线性代数性质：在定义了度量函数的向量空间中，可以用距离代表两个向量间的相似度。类似的，我们也可以用两个 Embedding Vector 间的距离代表其映射的词语的相似度。\n$$ Similarity(A,B)=D_{Euclidean}(A,B)=\\sqrt{ \\Sigma_{i=1}^n{(a_{i}-b_{i})^2} } \\\\ $$ 仅遵循单射条件只是完成了词语层面的抽象，机器仍然无法理解其背后的语义。为了能够用内积描述自然语言的相似度，Embedding必须让语义相似的单词在向量空间中接近（相对于语义差距大的）。比如在下面的例子中，“Sail”和“Ship”在向量空间中是接近的，但与“How”距离较远。\nEmbedding in Neural Network 神经网络中的嵌入层 许多神经网络处理的任务中，输入层往往是 One hot 编码的离散数据。在其组成的矩阵过于稀疏时，信息量低，计算成本高。嵌入层通过将这一输入映射至维数较低的向量，优化了计算过程，提高了计算效率。\n嵌入层本质上是一个可学习的权重矩阵，行数等于词汇表长度，列数等于预设的嵌入维度。通过损失函数和反向传播机制，不断调整嵌入矩阵中的数值，使得语义相近的单词在向量空间中更接近。\n嵌入的维度可以调整，具体取决于要升维还是降维。维数不够就加维度！\n在最后输出之前，产生的向量通常不会等于任何一个已知对应单词的嵌入向量，这个时候对其做一次模糊匹配，转换为各类别的概率分布，即每个单词匹配该向量的概率。最后输出概率最高的单词。\nInterpret and Use 解释与使用 神经网络可以类比为黑箱，可见的只有输入输出，而其学习、推理的过程是不透明的。就嵌入向量而言，一个单词的嵌入往往是几百维的浮点值，我们难以解释它的具体意义；另一方面，嵌入向量之间的距离也是通过不透明的学习过程决定的，我们只能猜测靠的近的两个向量具有语义上的相似性，而无法说明为什么某一对向量的距离比另一对近。这带来了解释上的困难。\n现代 LLM 通常在 TB 级别的数据上进行训练，数据集规模之庞大，导致嵌入词的规模和嵌入向量的维数巨大，带来了更为昂贵的存储、检索和计算开销。数千维的空间下，数据可视化极为困难，无法通过常规绘图手段（二维/三维坐标系）直观地展示数据。这带来了可视化的困难。\n如果为了优化模型或提升嵌入质量，需要研究人员对嵌入向量进行人为干预、调整，这个过程无疑是极为灾难的。为了应对这些困难，许多学者提出了各式各样的交互式可视化工具用来帮助用户探索嵌入空间，比如本篇介绍的 WizMap。\n📃 0x02 Previous Work 前人的工作 Scatter Plot 散点图 一个探索嵌入空间的方法是将嵌入降维后可视化在低维散点图中。Smilkov 等人在2016年提出了 Embedding Projector，允许用户使用 PCA（主成分分析）和 t-SNE（t-分布随机邻域嵌入）方法将高维嵌入投影到 2D 或 3D 空间中，从而直观地观察数据分布。\n这种基于散点图的方法可以较好地理解嵌入的局部结构，但面对大型数据集时，逐个检查嵌入数据点以理解嵌入空间的全局结构既费时又难以实现。\nContour Plot 等高线图 近年来也有学者提出基于等高线的可视化交互方法，Robertson 等人在2023年提出的 Angler 系统中将高维数据投影到二维平面，并以等高线的形式表示数据密度或相似度，使用户能够获得嵌入空间的整体概览，并通过叠加比较多个嵌入结果。\n这种基于等高线的方法可以快速获得对嵌入空间的全局概览，但限制了用户对嵌入局部结构的探索，且缺乏足够的视觉环境（Visual Context）。\nConclusion 结论 基于散点图的方法难以获取嵌入的全局概览，而基于等高线图的方法虽能展现数据密度，但缺乏对局部细节的刻画。两种方法各有局限。\nWizMap 旨在整合散点图与等高线图各自的优势，使用地图式交互设计为用户提供全面的视角，允许用户以不同粒度探索嵌入空间，“降低了解释和使用嵌入的门槛”（lowers the barrier to interpreting and using embeddings）。\n🔥0x03 Related Work 相关工作 Dimensionality Reduction 降维 如前文所述，嵌入向量的高维性为可视化带来了困难，而高维数据的可视化通常是应用降维技术将其投影至二维或三维空间，再使用常规的可视化方式进行处理。\n一些流行的降维技术包括 UMAP（均匀流形近似与投影）、t-SNE（t-分布随机邻域嵌入）和 PCA（主成分分析）。这些技术在维护嵌入的结构、随机性、参数敏感性、计算效率与复杂度方面各有利弊。针对不同结构、属性的数据权衡不同的降维方法，能够得到更优的降维效果。\n尽管各自降维技术存在诸多不同，但其输出均为低维嵌入表示，是形如(n_samples, n_components)的矩阵。在 WizMap 中，用户可以自由选择降维方式，以可视化投影后的嵌入。\nInteractive Embedding Visualization 交互式嵌入可视化 可视化工具的一些常见交互工具\u0026方式包括：\n缩放、旋转和平移 2D 或 3D 投影嵌入以探索和检查数据点特征，如 Embedding Projector 专门用于大规模（数百万级）散点图的绘制，如 regl-scatterplot 潜在空间制图，帮助用户理解不同区域的数据分布及其语义特征，如 Latent Space Cartography 此外，研究人员还设计了一些用于比较不同降维方法产生的嵌入空间的可视化工具：\n未给出链接的工具截至目前（2025/3/30）没有开源实现\n可视化两个嵌入之间的局部和全局相似性，如 embComp（Heimerl 等，2022） 追踪数据点在两个嵌入中的位置变化（使用星轨 Star Rail 可视化），如 Emblaze（Sivaraman 等，2022） 突出显示在嵌入中变化最大的点周围的邻域，如 embedding-comparator （Boggust 等，2022） 这些工具可以通过比较不同模型、不同算法生成的嵌入，比较嵌入表示之间的差异，并​分析嵌入的全局和局部结构，以评估模型的表示学习能力。\n与此相反，WizMap 通过提供不同粒度（全局-局部）的视觉上下文，帮助用户导航和解释大型嵌入空间的全局和局部结构。\n📄0x04 Multi-scale Embedding Summarization 多尺度嵌入摘要 Embedding Summarization（嵌入摘要）旨在从大型嵌入空间中提取核心信息，以帮助用户理解和探索数据的结构、分布及其重要特征\n生成嵌入摘要主要具有两个挑战：\n如何在大型数据集中有效地总结数百万级的数据点 如何选择要总结的嵌入区域（用户对不同大小和粒度的区域有不同的兴趣） WizMap 的开发者提出了一种新颖的方法，以自动生成大规模数据的多尺度嵌入摘要。\nMulti-resolution Quadtree Aggregation 多分辨率四叉树聚合 首先应用降维技术，将高维嵌入向量投影到二维平面上的点。从这些点出发，构建一颗四叉树。\n这颗四叉树的每一次划分将二维空间分为四个相等的正方形区域（叶节点），每个区域仅存在一个数据点。为了得到不同粒度级别的嵌入汇总，自底向上遍历树。在每次迭代中提取每个叶节点中嵌入的摘要，然后将最低级别的叶节点与其父节点合并。这个过程递归地进行，形成级别越来越高（图中自下而上）的叶节点，直到整个树最终合并为一个根节点。\n有点 2048 的思想在，了解图形学八叉树的同学应该理解起来没压力\n整个过程是预计算的，当用户在 WIZMAP 中缩放时，系统会自动将缩放映射到合适的嵌入摘要级别，实现多粒度摘要的动态切换。\n可以联想谷歌地图自适应缩放的做法\nScalable Leaf-level Summarization 可扩展叶级别摘要 形成四叉树聚合时，研究人员可以选择任何合适的方法来从叶节点总结嵌入。对于文本嵌入，开发者提出了基于块的 TF-IDF（t-TF-IDF），它将 TF-IDF（Term Frequency-Inverse Document Frequency）应用于从叶节点提取关键词（Sparck Jones，1972）。\nt-TF-IDF 通过将文档划分为多个“块”来计算词频（TF）将长文档 $d$ 划分为多个较小的块 $B_{i}$，对每个块计算块级 TF ： $t\\text{-} TF(t,B)=\\frac{词 t 在块 B 中的出现次数}{块 B 的总词数}$\n类似于基于类的 TF-IDF（c-TF-IDF），在计算 TF-IDF 分数之前将聚类中的文档合并为一个元文档（Grootendorst，2022）。将每个叶节点中的所有文档（即四叉树分区中的一个块）合并为一个元文档，并在所有叶节点上计算 TF-IDF 分数。最后，提取具有最高 t-TF-IDF 分数的关键词来总结叶节点中的嵌入。\n$t\\text{-}TF\\text{-}IDF(t,d)=\\max\\limits_{B\\in d}(t\\text{-}TF(t,B)\\times IDF(t))$，选取该词在所有块中权重最高的值，保留局部特征\n这种方法是可扩展的，并且与四叉树聚合相辅相成。由于文档合并是分层的，只需构建一次 n-gram 计数矩阵，并在每次聚合迭代中仅通过一次矩阵乘法进行更新。\n在 MacBook Pro 上，总结跨越三个粒度级别的 180 万个文本嵌入，只需大约 55 秒。 处理非文本数据的嵌入时，可以通过找到叶节点中与嵌入中心点最近的点来总结嵌入。\n🖥️User Interface 用户界面 结合 livedemo 和演示视频进行解释\nWizMap 的 UI 大致可以分为如下 3 个部分：\nMap View 地图视图 地图视图是 WIZMAP 的主要视图。它提供了一个熟悉的地图界面，允许用户平移和缩放以探索不同大小的嵌入区域。为了帮助用户轻松地调查嵌入的全局和局部结构，地图视图集成了三层可视化：\nContour：等高线轮廓展示嵌入分布，可视化嵌入全局结构 Label：标签展示嵌入摘要，可视化嵌入摘要 Scatter：散点展示嵌入点信息，可视化嵌入局部结构 分布轮廓（Distribution Contour）。使用核密度估计（KDE）（Rosenblatt，1956）来估计二维嵌入点的分布。以标准的多变量高斯核和 Silverman 带宽作为 KDE 模型（Silverman，2018）。\n核密度估计是一种非参数方法，通过对每个数据点施加核函数（$K$，带宽 $h$ 决定其平滑程度），并汇总所有核函数的贡献，估计总体的概率密度函数。​其数学表达式为：$\\hat{f}(x)=\\frac{1}{nh}\\Sigma_{i=1}^nK\\left( \\frac{x-x_{i}}{h} \\right)$\n在一个 200×200 的二维网格上计算分布似然，该网格的大小由所有嵌入点的范围决定。最后，将网格上的似然性可视化为一个等高线图，突出显示嵌入的密度分布。研究人员可以调整网格密度，通过平衡计算时间和等高线分辨率来调整它。\n多分辨率标签（Muti-resolution Labels），用户可以通过这些预计算的上下文标签，在各个粒度级别上动态地解释嵌入。当用户悬停在某个网格上时，将这部分通过四叉树聚合生成的摘要标签叠加到等高线图和散点图上。并能根据用户的当前缩放级别调整标签的瓦片（Tile）大小。\n此外，此视图还能够自动标记高密度嵌入点区域，通过显示靠近高概率轮廓多边形（high-probability contour polygons）几何中心四叉树瓦片的摘要实现。\n散点图（Scatter Plot），\n用二维散点图可视化所有嵌入点及其位置。用户可以指定每个嵌入点的颜色来编码额外的特征，例如嵌入类的颜色。此外，用户可以将鼠标悬停在散点上以显示其原始数据。\nControl Panel 控制面板 地图视图默认显示所有三个可视化层，用户可以通过控制面板中的按钮自定义视图显示。此外，WizMap 允许用户通过在地图视图中叠加它们来比较同一嵌入空间中的多个嵌入组（Gleicher，2018）。对于包含时间的嵌入，用户可以使用控制面板右侧的滑块来观察嵌入随时间的变化。\nSearch Panel 搜索面板 搜索和筛选可以帮助用户发现有趣的嵌入模式并测试他们对嵌入结构的假设（Carter 等人，2019 年）。在 WizMap 中，用户可以使用搜索面板搜索包含指定单词的文本嵌入。面板显示搜索结果列表，地图视图高亮显示相应的嵌入点。\nScalable \u0026 Open-source Implementation 可扩展且开源的实现 WizMap 可扩展至数百万个嵌入点，无需后端服务器。利用现代网络技术，特别是 WebGL 通过 regl API（Lysenko，2016 年）渲染嵌入点。还使用 Web Workers 和 Streams API 来实现大嵌入点的流式传输。将嵌入与渲染并行处理。\n为了实现快速全文搜索，应用了 FlexSearch（Wilkerling，2019）的上下文索引评分算法。使用 D3（Bostock 等，2011）进行其他可视化，并使用 scikit-learn（Pedregosa 等，2011）进行核密度估计（KDE）。为了 WizMap 可以轻松集成到用户当前的流程中（Wang 等，2023），应用 NOVA（Wang 等，2022b）使 WIZMAP 在笔记本中可用。用户还可以通过唯一的 URL 与协作者共享他们的嵌入图。\nWizMap 的开发者提供详细的教程，帮助用户处理嵌入，并且将 WizMap 开源，以支持嵌入探索工具的未来研究和开发。\n🔧Usage Scenarios 使用场景 Exploring ACL Research Topic Trends 探索 ACL 研究趋势 海伦（Helen）是一位科学历史学家，她利用 ACL Anthology 数据集研究 NLP 领域的演变。她提取了 63k 篇论文的标题和摘要，并使用 MPNet 生成 768 维嵌入向量。然后，她通过 UMAP 降维，并调整参数以优化投影分布。她利用 WizMap 生成嵌入摘要、KDE 分布和流式数据的 JSON 文件，并基于年份特征分析 NLP 研究主题的时间演变。\n在可视化分析中，海伦通过缩放和平移探索嵌入结构，并使用搜索功能查找特定关键词的论文。她发现不同的研究方向形成了独立簇，例如翻译、摘要和医疗 NLP。在播放嵌入演变动画时，她观察到 NLP 研究主题的变化，如语法研究热度下降，而问答、讽刺、幽默和仇恨言论等新主题逐渐兴起。最终，她决定撰写一篇论文，探讨 NLP 研究趋势的演变。\nInvestigating Text-to-Image Model Usage 探究文生图模型的使用 Bob 是一名机器学习研究员，致力于改进文生图的模型。他使用 DiffusionDB 数据集，分析用户的文本提示（prompt）与生成图像的关系。为此，他采用 CLIP 将文本和图像编码为 768 维嵌入，并利用 UMAP 降维到 2D 空间。随后，他使用 WizMap 进行可视化，探索 360 万个嵌入的结构。\n在嵌入探索过程中，Bob 发现提示主要分为艺术和摄影两个类别，并进一步识别出摄影类别中的两个小簇：非人类物体和名人。随后，他通过比较文本嵌入与图像嵌入的分布，发现“电影”相关的文本嵌入密度较低，而“艺术肖像”在图像嵌入中密度较高，这可能表明 Stable Diffusion 在生成逼真的人脸图像方面存在一定的局限性。Bob 对这个发现感到满意，并将其用于改进训练数据。\n🛤️ Future Work and Conclusion 未来工作与结论 WizMap 集成基于四叉树的嵌入摘要技术，方便用户解释多种粒度级别的嵌入，展现出为机器学习领域提供可视化嵌入的潜力。开发者同时也反思开发过程中的不足，并提炼出了未来的研究方向：\n用户研究，探究用户眼中自适应的视图粒度变换的有效性 自动洞察，基于四叉树的方法对瓦片大小敏感，需要更稳健的嵌入摘要方法 增强比较，叠加等高线的方法在局部比较上劣于其它技术，如并列（Juxtaposition）和显式编码（Explicit Encoding） 📉 Broader Impact 更广泛的影响 不良分子可能会恶意利用从 WizMap 中获得的见解。例如，研究表明机器学习嵌入包含社会偏见（Bolukbasi 等人，2016 年）。因此，不良分子可以通过注入已知与性别和种族偏见相关的嵌入来操纵和破坏机器学习预测。\n📝 After words 个人拙见，主要描述除投影算法和开发者已反思的不足之外的个人看法。可能是一些细枝末节的角度，如有不当，还望海涵\n搜索功能允许搜索关键词并高亮相关嵌入，但没有提供更高级的查询功能，如按类别筛选、模糊匹配或复杂逻辑查询，并根据结果相关度分不同级别高亮嵌入。\n观察嵌入在的时间上的演变时，无法选取播放区域和控制动画播放速度，需要在时间上细致分析时可能显得不够灵活。\n原文中提到用户可以指定每个嵌入点的颜色来编码额外的特征，比如嵌入类（Users can specify the color of each embedding point to encode additional features, such as the class of embeddings.）。但在 live demo 中并没有为嵌入提供手动标记和分类的操作，这一步骤是否发生在可视化之前？\n总体上仍然是极为优秀的可视化工具，感谢开发者们的工作。\n","wordCount":"566","inLanguage":"zh","datePublished":"2025-03-21T00:00:00Z","dateModified":"2025-03-21T00:00:00Z","author":{"@type":"Person","name":"The Only Problem"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://congyuxiaoyoudao.github.io/posts/assignments/analysis-of-wizmap-scalable-interactive-visualization/"},"publisher":{"@type":"Organization","name":"The Only Problem's Blog","logo":{"@type":"ImageObject","url":"https://congyuxiaoyoudao.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://congyuxiaoyoudao.github.io/ accesskey=h title="The Only Problem's Blog (Alt + H)">The Only Problem's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://congyuxiaoyoudao.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://congyuxiaoyoudao.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://congyuxiaoyoudao.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://congyuxiaoyoudao.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://congyuxiaoyoudao.github.io/>主页</a>&nbsp;»&nbsp;<a href=https://congyuxiaoyoudao.github.io/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://congyuxiaoyoudao.github.io/posts/assignments/>Assignments</a></div><h1 class="post-title entry-hint-parent">Assignment 1. Analysis of WizMap Scalable Interactive Visualization</h1><div class=post-meta><span title='2025-03-21 00:00:00 +0000 UTC'>三月 21, 2025</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;The Only Problem</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#-0x00-to-begin-with aria-label="🚩 0x00 To begin with">🚩 0x00 To begin with</a></li><li><a href=#-0x01-what-is-llm-embedding aria-label="🤔 0x01 What is LLM Embedding">🤔 0x01 What is LLM Embedding</a><ul><li><a href=#concept-of-embedding-%e5%b5%8c%e5%85%a5%e7%9a%84%e6%a6%82%e5%bf%b5 aria-label="Concept of Embedding 嵌入的概念">Concept of Embedding 嵌入的概念</a></li><li><a href=#semantic-baseed-encoding-%e5%9f%ba%e4%ba%8e%e8%af%8d%e4%b9%89%e7%9a%84%e7%bc%96%e7%a0%81 aria-label="Semantic Baseed Encoding 基于词义的编码">Semantic Baseed Encoding 基于词义的编码</a></li><li><a href=#embedding-in-neural-network-%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e4%b8%ad%e7%9a%84%e5%b5%8c%e5%85%a5%e5%b1%82 aria-label="Embedding in Neural Network 神经网络中的嵌入层">Embedding in Neural Network 神经网络中的嵌入层</a></li><li><a href=#interpret-and-use-%e8%a7%a3%e9%87%8a%e4%b8%8e%e4%bd%bf%e7%94%a8 aria-label="Interpret and Use 解释与使用">Interpret and Use 解释与使用</a></li></ul></li><li><a href=#-0x02-previous-work-%e5%89%8d%e4%ba%ba%e7%9a%84%e5%b7%a5%e4%bd%9c aria-label="📃 0x02 Previous Work 前人的工作">📃 0x02 Previous Work 前人的工作</a><ul><li><a href=#scatter-plot-%e6%95%a3%e7%82%b9%e5%9b%be aria-label="Scatter Plot 散点图">Scatter Plot 散点图</a></li><li><a href=#contour-plot-%e7%ad%89%e9%ab%98%e7%ba%bf%e5%9b%be aria-label="Contour Plot 等高线图">Contour Plot 等高线图</a></li><li><a href=#conclusion-%e7%bb%93%e8%ae%ba aria-label="Conclusion 结论">Conclusion 结论</a></li></ul></li><li><a href=#0x03-related-work-%e7%9b%b8%e5%85%b3%e5%b7%a5%e4%bd%9c aria-label="🔥0x03 Related Work 相关工作">🔥0x03 Related Work 相关工作</a><ul><li><a href=#dimensionality-reduction-%e9%99%8d%e7%bb%b4 aria-label="Dimensionality Reduction 降维">Dimensionality Reduction 降维</a></li><li><a href=#interactive-embedding-visualization-%e4%ba%a4%e4%ba%92%e5%bc%8f%e5%b5%8c%e5%85%a5%e5%8f%af%e8%a7%86%e5%8c%96 aria-label="Interactive Embedding Visualization 交互式嵌入可视化">Interactive Embedding Visualization 交互式嵌入可视化</a></li></ul></li><li><a href=#0x04-multi-scale-embedding-summarization-%e5%a4%9a%e5%b0%ba%e5%ba%a6%e5%b5%8c%e5%85%a5%e6%91%98%e8%a6%81 aria-label="📄0x04 Multi-scale Embedding Summarization 多尺度嵌入摘要">📄0x04 Multi-scale Embedding Summarization 多尺度嵌入摘要</a><ul><li><a href=#multi-resolution-quadtree-aggregation-%e5%a4%9a%e5%88%86%e8%be%a8%e7%8e%87%e5%9b%9b%e5%8f%89%e6%a0%91%e8%81%9a%e5%90%88 aria-label="Multi-resolution Quadtree Aggregation 多分辨率四叉树聚合">Multi-resolution Quadtree Aggregation 多分辨率四叉树聚合</a></li><li><a href=#scalable-leaf-level-summarization-%e5%8f%af%e6%89%a9%e5%b1%95%e5%8f%b6%e7%ba%a7%e5%88%ab%e6%91%98%e8%a6%81 aria-label="Scalable Leaf-level Summarization 可扩展叶级别摘要">Scalable Leaf-level Summarization 可扩展叶级别摘要</a></li></ul></li><li><a href=#user-interface-%e7%94%a8%e6%88%b7%e7%95%8c%e9%9d%a2 aria-label="🖥️User Interface 用户界面">🖥️User Interface 用户界面</a><ul><li><a href=#map-view-%e5%9c%b0%e5%9b%be%e8%a7%86%e5%9b%be aria-label="Map View 地图视图">Map View 地图视图</a></li><li><a href=#control-panel-%e6%8e%a7%e5%88%b6%e9%9d%a2%e6%9d%bf aria-label="Control Panel 控制面板">Control Panel 控制面板</a></li><li><a href=#search-panel-%e6%90%9c%e7%b4%a2%e9%9d%a2%e6%9d%bf aria-label="Search Panel 搜索面板">Search Panel 搜索面板</a></li><li><a href=#scalable--open-source-implementation-%e5%8f%af%e6%89%a9%e5%b1%95%e4%b8%94%e5%bc%80%e6%ba%90%e7%9a%84%e5%ae%9e%e7%8e%b0 aria-label="Scalable & Open-source Implementation 可扩展且开源的实现">Scalable & Open-source Implementation 可扩展且开源的实现</a></li></ul></li><li><a href=#usage-scenarios-%e4%bd%bf%e7%94%a8%e5%9c%ba%e6%99%af aria-label="🔧Usage Scenarios 使用场景">🔧Usage Scenarios 使用场景</a><ul><li><a href=#exploring-acl-research-topic-trends-%e6%8e%a2%e7%b4%a2-acl-%e7%a0%94%e7%a9%b6%e8%b6%8b%e5%8a%bf aria-label="Exploring ACL Research Topic Trends 探索 ACL 研究趋势">Exploring ACL Research Topic Trends 探索 ACL 研究趋势</a></li><li><a href=#investigating-text-to-image-model-usage--%e6%8e%a2%e7%a9%b6%e6%96%87%e7%94%9f%e5%9b%be%e6%a8%a1%e5%9e%8b%e7%9a%84%e4%bd%bf%e7%94%a8 aria-label="Investigating Text-to-Image Model Usage 探究文生图模型的使用">Investigating Text-to-Image Model Usage 探究文生图模型的使用</a></li></ul></li><li><a href=#-future-work-and-conclusion-%e6%9c%aa%e6%9d%a5%e5%b7%a5%e4%bd%9c%e4%b8%8e%e7%bb%93%e8%ae%ba aria-label="🛤️ Future Work and Conclusion 未来工作与结论">🛤️ Future Work and Conclusion 未来工作与结论</a></li><li><a href=#-broader-impact-%e6%9b%b4%e5%b9%bf%e6%b3%9b%e7%9a%84%e5%bd%b1%e5%93%8d aria-label="📉 Broader Impact 更广泛的影响">📉 Broader Impact 更广泛的影响</a></li><li><a href=#-after-words aria-label="📝 After words">📝 After words</a></li></ul></div></details></div><div class=post-content><blockquote><p>由于嵌入式模型的不透明、高维度以及大规模现代数据集的限制，对其进行解释和使用极具挑战性。Zijie J. Wang 等开发了 WizMap，一个交互式可视化工具，允许用户轻松探索和解释嵌入式大模型</p></blockquote><hr><h2 id=-0x00-to-begin-with>🚩 0x00 To begin with<a hidden class=anchor aria-hidden=true href=#-0x00-to-begin-with>#</a></h2><blockquote><p>应可视化课程要求，本篇旨在对原论文项目进行粗浅的翻译&介绍&分析，仅作学习之用
论文名：<em>WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings</em>
作者：Zijie J. Wang, Fred Hohman, Duen Horng Chau</p></blockquote><p>这篇文章将会包含以下内容：</p><ul><li><input checked disabled type=checkbox> Embedding Model 及其局限</li><li><input checked disabled type=checkbox> 前人的交互可视化工具<ul><li><input checked disabled type=checkbox> 散点图</li><li><input checked disabled type=checkbox> 等高线图</li></ul></li><li><input checked disabled type=checkbox> WizMap 的目的及意义</li><li><input checked disabled type=checkbox> WizMap 的实现分析</li><li><input checked disabled type=checkbox> 笔者的看法</li></ul><p><strong>For reference</strong>👇：</p><ul><li>📖 原论文地址：
<a href="https://arxiv.org/abs/2306.09328#:~:text=With%20a%20novel%20multi-resolution%20embedding%20summarization%20method%20and,to%20navigate%20and%20interpret%20embedding%20spaces%20with%20ease.">[2306.09328] WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings</a></li><li>📺 原演示视频：
<a href="https://www.youtube.com/watch?v=8fJG87QVceQ">Demo Video &ldquo;WizMAP: Scalable Interactive Visualization for Exploring Large ML Embeddings&rdquo;</a></li><li>🔧 演示地址：
<a href=https://poloclub.github.io/wizmap/>WizMap</a></li><li>📖
<a href=https://zhuanlan.zhihu.com/p/643560252>没有思考过 Embedding，不足以谈 AI</a></li><li>📺
<a href="https://www.youtube.com/watch?v=my5wFNQpFO0">Machine Learning Crash Course: Embeddings</a></li><li>📺
<a href="https://www.youtube.com/watch?v=yaqoHhyiybw&amp;t=248s">14 Embedding Projector</a></li></ul><hr><h2 id=-0x01-what-is-llm-embedding>🤔 0x01 What is LLM Embedding<a hidden class=anchor aria-hidden=true href=#-0x01-what-is-llm-embedding>#</a></h2><blockquote><p>为了让没有接触过机器学习的读者更容易理解原论文的工作，笔者加上了此节</p></blockquote><h3 id=concept-of-embedding-嵌入的概念><strong>Concept of Embedding 嵌入的概念</strong><a hidden class=anchor aria-hidden=true href=#concept-of-embedding-嵌入的概念>#</a></h3><blockquote><p>在数学上，Embedding 代表一个映射关系：$f:X\to Y$，该关系是同构的，即在单射条件下保持数学结构（加性、乘法等）；在机器学习领域，用于将数据源映射到另外一个空间，数据源可以来自于文本、图像甚至视频，这里以文本为例</p></blockquote><p>对于人而言，语言有丰富的上下文、语法规则、多义性、文化背景等特性。而对于机器而言，语言只不过是 0 和 1 。如果想让机器能够“理解”自然语言，就需要对文本信息进行抽象编码。</p><p>Embedding（嵌入）就提供了对自然语言的一层抽象，将离散的文本输入转换为<strong>连续的向量表示</strong>。这种向量表示能够捕捉文本的语义（上下文）信息，使其可以被 LLM 处理、存储和计算。</p><h3 id=semantic-baseed-encoding-基于词义的编码><strong>Semantic Baseed Encoding 基于词义的编码</strong><a hidden class=anchor aria-hidden=true href=#semantic-baseed-encoding-基于词义的编码>#</a></h3><p>Embedding 对自然语言到多维向量空间的映射必须是一一映射，也即每个词语映射到一个唯一向量，不同词语映射的向量不同。这种操作有效降低了因为自然语言中可能存在的“多词一义”、“一词多义”而导致的复杂性，也是编码需要遵循的条件之一。</p><p>映射到多维向量空间主要有两个理由：</p><p>1.可以对应单词<strong>多维度特征</strong>，也即单词不同层面的属性。相较于标量，向量能够承载更多的信息，Embedding 就像把这些属性“嵌入”到向量各维度的值的过程。比如说 apple 可以表示为这样：</p><table><thead><tr><th>Word</th><th>Animal</th><th>Big</th><th>Red</th><th>Expensive</th><th>&mldr;</th></tr></thead><tbody><tr><td>apple</td><td>-0.5</td><td>0.1</td><td>0.7</td><td>0.3</td><td>&mldr;</td></tr></tbody></table><blockquote><p>属性只是举个例子，不太恰当敬请谅解</p></blockquote><p>然而如何确定能描述全部自然语言词语的所有维度是困难的。即使是同一词语，在不同上下文的意义也可能不同，与其大费周章找到一套固定的维度，不如将词语定义在其处于的上下文中，用词与词之间的关系定义词。</p><blockquote><ul><li><strong>Apple</strong> pie is my favorite dessert during the holidays.</li><li>Discover the innovative world of <strong>Apple</strong> and shop everything iPhone&mldr;</li></ul></blockquote><p>在第一句中，Apple 的含义与 Pear 接近，但在第二句中却与 Huawei 接近。</p><p>2.可以对向量（准确而言是向量之间的关系）进行度量。这里就用到一些基本的线性代数性质：在定义了度量函数的向量空间中，可以用距离代表两个向量间的相似度。类似的，我们也可以用两个 Embedding Vector 间的距离代表其映射的词语的相似度。</p><div>$$
Similarity(A,B)=D_{Euclidean}(A,B)=\sqrt{ \Sigma_{i=1}^n{(a_{i}-b_{i})^2} } \\
$$</div><p>仅遵循单射条件只是完成了词语层面的抽象，机器仍然无法理解其背后的语义。为了能够用内积描述自然语言的相似度，Embedding必须让语义相似的单词在向量空间中接近（相对于语义差距大的）。比如在下面的例子中，“Sail”和“Ship”在向量空间中是接近的，但与“How”距离较远。</p><p><img alt="Google Machine Learning Crash Course: Embeddings" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503221405888.png#center></p><h3 id=embedding-in-neural-network-神经网络中的嵌入层><strong>Embedding in Neural Network 神经网络中的嵌入层</strong><a hidden class=anchor aria-hidden=true href=#embedding-in-neural-network-神经网络中的嵌入层>#</a></h3><p>许多神经网络处理的任务中，输入层往往是 One hot 编码的离散数据。在其组成的矩阵过于稀疏时，信息量低，计算成本高。嵌入层通过将这一输入映射至维数<strong>较低</strong>的向量，优化了计算过程，提高了计算效率。</p><p><img alt="Google Machine Learning Crash Course: Embeddings" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503221337385.png#center></p><p>嵌入层本质上是一个可学习的权重矩阵，行数等于词汇表长度，列数等于预设的嵌入维度。通过损失函数和反向传播机制，不断调整嵌入矩阵中的数值，使得语义相近的单词在向量空间中更接近。</p><blockquote><p>嵌入的维度可以调整，具体取决于要升维还是降维。维数不够就加维度！</p></blockquote><p>在最后输出之前，产生的向量通常不会等于任何一个已知对应单词的嵌入向量，这个时候对其做一次模糊匹配，转换为各类别的概率分布，即每个单词匹配该向量的概率。最后输出概率最高的单词。</p><h3 id=interpret-and-use-解释与使用><strong>Interpret and Use 解释与使用</strong><a hidden class=anchor aria-hidden=true href=#interpret-and-use-解释与使用>#</a></h3><p>神经网络可以类比为黑箱，可见的只有输入输出，而其学习、推理的过程是不透明的。就嵌入向量而言，一个单词的嵌入往往是几百维的浮点值，我们难以解释它的具体意义；另一方面，嵌入向量之间的距离也是通过不透明的学习过程决定的，我们只能猜测靠的近的两个向量具有语义上的相似性，而无法说明为什么某一对向量的距离比另一对近。这带来了解释上的困难。</p><p>现代 LLM 通常在 TB 级别的数据上进行训练，数据集规模之庞大，导致嵌入词的规模和嵌入向量的维数巨大，带来了更为昂贵的存储、检索和计算开销。数千维的空间下，数据可视化极为困难，无法通过常规绘图手段（二维/三维坐标系）直观地展示数据。这带来了可视化的困难。</p><p>如果为了优化模型或提升嵌入质量，需要研究人员对嵌入向量进行人为干预、调整，这个过程无疑是极为灾难的。为了应对这些困难，许多学者提出了各式各样的交互式可视化工具用来帮助用户探索嵌入空间，比如本篇介绍的 WizMap。</p><hr><h2 id=-0x02-previous-work-前人的工作>📃 0x02 Previous Work 前人的工作<a hidden class=anchor aria-hidden=true href=#-0x02-previous-work-前人的工作>#</a></h2><h3 id=scatter-plot-散点图><strong>Scatter Plot 散点图</strong><a hidden class=anchor aria-hidden=true href=#scatter-plot-散点图>#</a></h3><p>一个探索嵌入空间的方法是将嵌入降维后可视化在低维散点图中。Smilkov 等人在2016年提出了 Embedding Projector，允许用户使用 PCA（主成分分析）和 t-SNE（t-分布随机邻域嵌入）方法将高维嵌入投影到 2D 或 3D 空间中，从而直观地观察数据分布。</p><p><img alt="https://www.youtube.com/watch?v=yaqoHhyiybw&amp;t=248s" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503281941215.gif#center></p><p>这种基于散点图的方法可以较好地理解嵌入的局部结构，但面对大型数据集时，逐个检查嵌入数据点以理解嵌入空间的全局结构既费时又难以实现。</p><h3 id=contour-plot-等高线图><strong>Contour Plot 等高线图</strong><a hidden class=anchor aria-hidden=true href=#contour-plot-等高线图>#</a></h3><p>近年来也有学者提出基于等高线的可视化交互方法，Robertson 等人在2023年提出的 Angler 系统中将高维数据投影到二维平面，并以等高线的形式表示数据密度或相似度，使用户能够获得嵌入空间的整体概览，并通过叠加比较多个嵌入结果。</p><p><img alt="https://github.com/apple/ml-translate-vis?tab=readme-ov-file" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503281959646.gif#center></p><p>这种基于等高线的方法可以快速获得对嵌入空间的全局概览，但限制了用户对嵌入局部结构的探索，且缺乏足够的视觉环境（Visual Context）。</p><h3 id=conclusion-结论><strong>Conclusion 结论</strong><a hidden class=anchor aria-hidden=true href=#conclusion-结论>#</a></h3><p>基于散点图的方法难以获取嵌入的全局概览，而基于等高线图的方法虽能展现数据密度，但缺乏对局部细节的刻画。两种方法各有局限。</p><p>WizMap 旨在整合散点图与等高线图各自的优势，使用地图式交互设计为用户提供全面的视角，允许用户以不同粒度探索嵌入空间，“降低了解释和使用嵌入的门槛”（lowers the barrier to interpreting and using embeddings）。</p><hr><h2 id=0x03-related-work-相关工作>🔥0x03 Related Work 相关工作<a hidden class=anchor aria-hidden=true href=#0x03-related-work-相关工作>#</a></h2><h3 id=dimensionality-reduction-降维><strong>Dimensionality Reduction 降维</strong><a hidden class=anchor aria-hidden=true href=#dimensionality-reduction-降维>#</a></h3><p>如前文所述，嵌入向量的高维性为可视化带来了困难，而高维数据的可视化通常是应用降维技术将其投影至二维或三维空间，再使用常规的可视化方式进行处理。</p><p>一些流行的降维技术包括 UMAP（均匀流形近似与投影）、t-SNE（t-分布随机邻域嵌入）和 PCA（主成分分析）。这些技术在维护嵌入的结构、随机性、参数敏感性、计算效率与复杂度方面各有利弊。针对不同结构、属性的数据权衡不同的降维方法，能够得到更优的降维效果。</p><p>尽管各自降维技术存在诸多不同，但其输出均为低维嵌入表示，是形如(n_samples, n_components)的矩阵。在 WizMap 中，用户可以自由选择降维方式，以可视化投影后的嵌入。</p><h3 id=interactive-embedding-visualization-交互式嵌入可视化><strong>Interactive Embedding Visualization 交互式嵌入可视化</strong><a hidden class=anchor aria-hidden=true href=#interactive-embedding-visualization-交互式嵌入可视化>#</a></h3><p>可视化工具的一些常见交互工具&方式包括：</p><ul><li>缩放、旋转和平移 2D 或 3D 投影嵌入以探索和检查数据点特征，如
<a href="https://www.youtube.com/watch?v=yaqoHhyiybw">Embedding Projector</a></li><li>专门用于大规模（数百万级）散点图的绘制，如
<a href=https://github.com/flekschas/regl-scatterplot>regl-scatterplot</a></li></ul><p><img alt="regl-scatterplot. Lekschas 2023" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503301656441.gif#center></p><ul><li>潜在空间制图，帮助用户理解不同区域的数据分布及其语义特征，如
<a href="https://www.youtube.com/watch?v=war0DRbRGNE">Latent Space Cartography</a></li></ul><p><img alt="Latent Space Cartography. Yang Liu 2019" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503301645671.png#center></p><p>此外，研究人员还设计了一些用于比较不同降维方法产生的嵌入空间的可视化工具：</p><blockquote><p>未给出链接的工具截至目前（2025/3/30）没有开源实现</p></blockquote><ul><li>可视化两个嵌入之间的局部和全局相似性，如 embComp（Heimerl 等，2022）</li><li>追踪数据点在两个嵌入中的位置变化（使用星轨 Star Rail 可视化），如 Emblaze（Sivaraman 等，2022）</li><li>突出显示在嵌入中变化最大的点周围的邻域，如
<a href="https://github.com/mitvis/embedding-comparator?utm_source=chatgpt.com">embedding-comparator</a>
（Boggust 等，2022）</li></ul><p>这些工具可以通过比较不同模型、不同算法生成的嵌入，比较嵌入表示之间的差异，并​分析嵌入的全局和局部结构，以评估模型的表示学习能力。</p><p>与此相反，WizMap 通过提供不同粒度（全局-局部）的视觉上下文，帮助用户导航和解释大型嵌入空间的全局和局部结构。</p><hr><h2 id=0x04-multi-scale-embedding-summarization-多尺度嵌入摘要>📄0x04 Multi-scale Embedding Summarization 多尺度嵌入摘要<a hidden class=anchor aria-hidden=true href=#0x04-multi-scale-embedding-summarization-多尺度嵌入摘要>#</a></h2><blockquote><p>Embedding Summarization（嵌入摘要）旨在从大型嵌入空间中提取核心信息，以帮助用户理解和探索数据的结构、分布及其重要特征</p></blockquote><p>生成嵌入摘要主要具有两个挑战：</p><ul><li>如何在大型数据集中有效地总结数百万级的数据点</li><li>如何选择要总结的嵌入区域（用户对不同大小和粒度的区域有不同的兴趣）</li></ul><p>WizMap 的开发者提出了一种新颖的方法，以自动生成大规模数据的多尺度嵌入摘要。</p><h3 id=multi-resolution-quadtree-aggregation-多分辨率四叉树聚合><strong>Multi-resolution Quadtree Aggregation 多分辨率四叉树聚合</strong><a hidden class=anchor aria-hidden=true href=#multi-resolution-quadtree-aggregation-多分辨率四叉树聚合>#</a></h3><p>首先应用降维技术，将高维嵌入向量投影到二维平面上的点。从这些点出发，构建一颗四叉树。</p><p><img alt=递归划分空间的二叉树 loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503301735904.png#center></p><p>这颗四叉树的每一次划分将二维空间分为四个相等的正方形区域（叶节点），每个区域仅存在一个数据点。为了得到不同粒度级别的嵌入汇总，自底向上遍历树。在每次迭代中提取每个叶节点中嵌入的摘要，然后将最低级别的叶节点与其父节点合并。这个过程递归地进行，形成级别越来越高（图中自下而上）的叶节点，直到整个树最终合并为一个根节点。</p><blockquote><p>有点 2048 的思想在，了解图形学八叉树的同学应该理解起来没压力</p></blockquote><p>整个过程是预计算的，当用户在 WIZMAP 中缩放时，系统会自动将缩放映射到合适的嵌入摘要级别，实现多粒度摘要的动态切换。</p><p><img alt=多粒度摘要 loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503302304143.png#center></p><blockquote><p>可以联想谷歌地图自适应缩放的做法</p></blockquote><h3 id=scalable-leaf-level-summarization-可扩展叶级别摘要><strong>Scalable Leaf-level Summarization 可扩展叶级别摘要</strong><a hidden class=anchor aria-hidden=true href=#scalable-leaf-level-summarization-可扩展叶级别摘要>#</a></h3><p>形成四叉树聚合时，研究人员可以选择任何合适的方法来从叶节点总结嵌入。对于文本嵌入，开发者提出了基于块的 TF-IDF（t-TF-IDF），它将 TF-IDF（Term Frequency-Inverse Document Frequency）应用于从叶节点提取关键词（Sparck Jones，1972）。</p><blockquote><p>t-TF-IDF 通过将文档划分为多个“块”来计算词频（TF）将长文档 $d$ 划分为多个较小的块 $B_{i}$，对每个块计算块级 TF ： $t\text{-} TF(t,B)=\frac{词 t 在块 B 中的出现次数}{块 B 的总词数}$</p></blockquote><p>类似于基于类的 TF-IDF（c-TF-IDF），在计算 TF-IDF 分数之前将聚类中的文档合并为一个元文档（Grootendorst，2022）。将每个叶节点中的所有文档（即四叉树分区中的一个块）合并为一个元文档，并在所有叶节点上计算 TF-IDF 分数。最后，提取具有最高 t-TF-IDF 分数的关键词来总结叶节点中的嵌入。</p><blockquote><p>$t\text{-}TF\text{-}IDF(t,d)=\max\limits_{B\in d}(t\text{-}TF(t,B)\times IDF(t))$，选取该词在所有块中权重最高的值，保留局部特征</p></blockquote><p>这种方法是可扩展的，并且与四叉树聚合相辅相成。由于文档合并是分层的，只需构建一次 n-gram 计数矩阵，并在每次聚合迭代中仅通过一次矩阵乘法进行更新。</p><p>在 MacBook Pro 上，总结跨越三个粒度级别的 180 万个文本嵌入，只需大约 55 秒。 处理非文本数据的嵌入时，可以通过找到叶节点中与嵌入中心点最近的点来总结嵌入。</p><hr><h2 id=user-interface-用户界面>🖥️User Interface 用户界面<a hidden class=anchor aria-hidden=true href=#user-interface-用户界面>#</a></h2><blockquote><p>结合 livedemo 和演示视频进行解释</p></blockquote><p>WizMap 的 UI 大致可以分为如下 3 个部分：</p><p><img alt="WizMap livedemo" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503311014814.png#center></p><h3 id=map-view-地图视图><strong>Map View 地图视图</strong><a hidden class=anchor aria-hidden=true href=#map-view-地图视图>#</a></h3><p>地图视图是 WIZMAP 的主要视图。它提供了一个熟悉的地图界面，允许用户平移和缩放以探索不同大小的嵌入区域。为了帮助用户轻松地调查嵌入的全局和局部结构，地图视图集成了三层可视化：</p><p><img alt="WizMap demo video 地图视图" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503311024526.png#center></p><ul><li>Contour：等高线轮廓展示嵌入分布，可视化嵌入全局结构</li><li>Label：标签展示嵌入摘要，可视化嵌入摘要</li><li>Scatter：散点展示嵌入点信息，可视化嵌入局部结构</li></ul><p><strong>分布轮廓（Distribution Contour）</strong>。使用核密度估计（KDE）（Rosenblatt，1956）来估计二维嵌入点的分布。以标准的多变量高斯核和 Silverman 带宽作为 KDE 模型（Silverman，2018）。</p><blockquote><p>核密度估计是一种非参数方法，通过对每个数据点施加核函数（$K$，带宽 $h$ 决定其平滑程度），并汇总所有核函数的贡献，估计总体的概率密度函数。​其数学表达式为：$\hat{f}(x)=\frac{1}{nh}\Sigma_{i=1}^nK\left( \frac{x-x_{i}}{h} \right)$</p></blockquote><p>在一个 200×200 的二维网格上计算分布似然，该网格的大小由所有嵌入点的范围决定。最后，将网格上的似然性可视化为一个等高线图，突出显示嵌入的密度分布。研究人员可以调整网格密度，通过平衡计算时间和等高线分辨率来调整它。</p><p><strong>多分辨率标签（Muti-resolution Labels）</strong>，用户可以通过这些预计算的上下文标签，在各个粒度级别上动态地解释嵌入。当用户悬停在某个网格上时，将这部分通过四叉树聚合生成的摘要标签叠加到等高线图和散点图上。并能根据用户的当前缩放级别调整标签的瓦片（Tile）大小。</p><p><img alt="WizMap demo video 标签自适应缩放" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503311656045.gif#center></p><p>此外，此视图还能够自动标记高密度嵌入点区域，通过显示靠近高概率轮廓多边形（high-probability contour polygons）几何中心四叉树瓦片的摘要实现。</p><p><strong>散点图（Scatter Plot）</strong>，</p><p>用二维散点图可视化所有嵌入点及其位置。用户可以指定每个嵌入点的颜色来编码额外的特征，例如嵌入类的颜色。此外，用户可以将鼠标悬停在散点上以显示其原始数据。</p><p><img loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503311116834.png#center></p><h3 id=control-panel-控制面板><strong>Control Panel 控制面板</strong><a hidden class=anchor aria-hidden=true href=#control-panel-控制面板>#</a></h3><p>地图视图默认显示所有三个可视化层，用户可以通过控制面板中的按钮自定义视图显示。此外，WizMap 允许用户通过在地图视图中叠加它们来比较同一嵌入空间中的多个嵌入组（Gleicher，2018）。对于包含时间的嵌入，用户可以使用控制面板右侧的滑块来观察嵌入随时间的变化。</p><p><img alt="WizMap demo video 嵌入的时间演变" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503311650701.gif#center></p><h3 id=search-panel-搜索面板><strong>Search Panel 搜索面板</strong><a hidden class=anchor aria-hidden=true href=#search-panel-搜索面板>#</a></h3><p>搜索和筛选可以帮助用户发现有趣的嵌入模式并测试他们对嵌入结构的假设（Carter 等人，2019 年）。在 WizMap 中，用户可以使用搜索面板搜索包含指定单词的文本嵌入。面板显示搜索结果列表，地图视图高亮显示相应的嵌入点。</p><p><img alt="WizMap demo video 文本搜索" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503311132454.gif#center></p><h3 id=scalable--open-source-implementation-可扩展且开源的实现><strong>Scalable & Open-source Implementation 可扩展且开源的实现</strong><a hidden class=anchor aria-hidden=true href=#scalable--open-source-implementation-可扩展且开源的实现>#</a></h3><p>WizMap 可扩展至数百万个嵌入点，无需后端服务器。利用现代网络技术，特别是 WebGL 通过 regl API（Lysenko，2016 年）渲染嵌入点。还使用 Web Workers 和 Streams API 来实现大嵌入点的流式传输。将嵌入与渲染并行处理。</p><p>为了实现快速全文搜索，应用了 FlexSearch（Wilkerling，2019）的上下文索引评分算法。使用 D3（Bostock 等，2011）进行其他可视化，并使用 scikit-learn（Pedregosa 等，2011）进行核密度估计（KDE）。为了 WizMap 可以轻松集成到用户当前的流程中（Wang 等，2023），应用 NOVA（Wang 等，2022b）使 WIZMAP 在笔记本中可用。用户还可以通过唯一的 URL 与协作者共享他们的嵌入图。</p><p>WizMap 的开发者提供详细的教程，帮助用户处理嵌入，并且将 WizMap 开源，以支持嵌入探索工具的未来研究和开发。</p><hr><h2 id=usage-scenarios-使用场景>🔧Usage Scenarios 使用场景<a hidden class=anchor aria-hidden=true href=#usage-scenarios-使用场景>#</a></h2><h3 id=exploring-acl-research-topic-trends-探索-acl-研究趋势><strong>Exploring ACL Research Topic Trends 探索 ACL 研究趋势</strong><a hidden class=anchor aria-hidden=true href=#exploring-acl-research-topic-trends-探索-acl-研究趋势>#</a></h3><p>海伦（Helen）是一位科学历史学家，她利用 ACL Anthology 数据集研究 NLP 领域的演变。她提取了 63k 篇论文的标题和摘要，并使用 MPNet 生成 768 维嵌入向量。然后，她通过 UMAP 降维，并调整参数以优化投影分布。她利用 WizMap 生成嵌入摘要、KDE 分布和流式数据的 JSON 文件，并基于年份特征分析 NLP 研究主题的时间演变。</p><p>在可视化分析中，海伦通过缩放和平移探索嵌入结构，并使用搜索功能查找特定关键词的论文。她发现不同的研究方向形成了独立簇，例如翻译、摘要和医疗 NLP。在播放嵌入演变动画时，她观察到 NLP 研究主题的变化，如语法研究热度下降，而问答、讽刺、幽默和仇恨言论等新主题逐渐兴起。最终，她决定撰写一篇论文，探讨 NLP 研究趋势的演变。</p><p><img alt="WizMap 允许用户通过时间轴观察嵌入的演变" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503311719928.png#center></p><h3 id=investigating-text-to-image-model-usage--探究文生图模型的使用><strong>Investigating Text-to-Image Model Usage 探究文生图模型的使用</strong><a hidden class=anchor aria-hidden=true href=#investigating-text-to-image-model-usage--探究文生图模型的使用>#</a></h3><p>Bob 是一名机器学习研究员，致力于改进文生图的模型。他使用 DiffusionDB 数据集，分析用户的文本提示（prompt）与生成图像的关系。为此，他采用 CLIP 将文本和图像编码为 768 维嵌入，并利用 UMAP 降维到 2D 空间。随后，他使用 WizMap 进行可视化，探索 360 万个嵌入的结构。</p><p><img alt="WizMap demo video 叠加比较文本和图像的嵌入" loading=lazy src=https://raw.gitmirror.com/congyuxiaoyoudao/Picgo-ImageBed/main/Assignments/Assignment%201.WizMap/202503311734454.gif#center></p><p>在嵌入探索过程中，Bob 发现提示主要分为艺术和摄影两个类别，并进一步识别出摄影类别中的两个小簇：非人类物体和名人。随后，他通过比较文本嵌入与图像嵌入的分布，发现“电影”相关的文本嵌入密度较低，而“艺术肖像”在图像嵌入中密度较高，这可能表明 Stable Diffusion 在生成逼真的人脸图像方面存在一定的局限性。Bob 对这个发现感到满意，并将其用于改进训练数据。</p><hr><h2 id=-future-work-and-conclusion-未来工作与结论>🛤️ Future Work and Conclusion 未来工作与结论<a hidden class=anchor aria-hidden=true href=#-future-work-and-conclusion-未来工作与结论>#</a></h2><p>WizMap 集成基于四叉树的嵌入摘要技术，方便用户解释多种粒度级别的嵌入，展现出为机器学习领域提供可视化嵌入的潜力。开发者同时也反思开发过程中的不足，并提炼出了未来的研究方向：</p><ul><li>用户研究，探究用户眼中自适应的视图粒度变换的有效性</li><li>自动洞察，基于四叉树的方法对瓦片大小敏感，需要更稳健的嵌入摘要方法</li><li>增强比较，叠加等高线的方法在局部比较上劣于其它技术，如并列（Juxtaposition）和显式编码（Explicit Encoding）</li></ul><hr><h2 id=-broader-impact-更广泛的影响>📉 Broader Impact 更广泛的影响<a hidden class=anchor aria-hidden=true href=#-broader-impact-更广泛的影响>#</a></h2><p>不良分子可能会恶意利用从 WizMap 中获得的见解。例如，研究表明机器学习嵌入包含社会偏见（Bolukbasi 等人，2016 年）。因此，不良分子可以通过注入已知与性别和种族偏见相关的嵌入来操纵和破坏机器学习预测。</p><hr><h2 id=-after-words>📝 After words<a hidden class=anchor aria-hidden=true href=#-after-words>#</a></h2><blockquote><p>个人拙见，主要描述除投影算法和开发者已反思的不足之外的个人看法。可能是一些细枝末节的角度，如有不当，还望海涵</p></blockquote><p>搜索功能允许搜索关键词并高亮相关嵌入，但没有提供更高级的查询功能，如按类别筛选、模糊匹配或复杂逻辑查询，并根据结果相关度分不同级别高亮嵌入。</p><p>观察嵌入在的时间上的演变时，无法选取播放区域和控制动画播放速度，需要在时间上细致分析时可能显得不够灵活。</p><p>原文中提到用户可以指定每个嵌入点的颜色来编码额外的特征，比如嵌入类（Users can specify the color of each embedding point to encode additional features, such as the class of embeddings.）。但在 live demo 中并没有为嵌入提供手动标记和分类的操作，这一步骤是否发生在可视化之前？</p><p>总体上仍然是极为优秀的可视化工具，感谢开发者们的工作。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://congyuxiaoyoudao.github.io/tags/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>可解释性</a></li><li><a href=https://congyuxiaoyoudao.github.io/tags/embedding/>Embedding</a></li><li><a href=https://congyuxiaoyoudao.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/>可视化</a></li></ul><nav class=paginav><a class=prev href=https://congyuxiaoyoudao.github.io/posts/assignments/a-review-of-realistic-water-waveform-simulation/><span class=title>« 上一页</span><br><span>Assignment 2. A Review of Realistic Water Waveform Simulation</span>
</a><a class=next href=https://congyuxiaoyoudao.github.io/posts/interludes/toon-intergrated-bxdf/><span class=title>下一页 »</span><br><span>Interlude 1. ToonIntergratedBxDF</span></a></nav></footer><div id=tw-comment></div><script>const getStoredTheme=()=>localStorage.getItem("pref-theme")==="light"?"light":"noborder_dark",setGiscusTheme=()=>{const e=e=>{const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")};e({setConfig:{theme:getStoredTheme()}})};document.addEventListener("DOMContentLoaded",()=>{const s={src:"https://giscus.app/client.js","data-repo":"congyuxiaoyoudao/congyuxiaoyoudao.github.io","data-repo-id":"","data-category":"Announcements","data-category-id":"","data-mapping":"pathname","data-strict":"0","data-reactions-enabled":"","data-emit-metadata":"","data-input-position":"","data-theme":getStoredTheme(),"data-lang":"zh-CN","data-loading":"lazy",crossorigin:"anonymous"},e=document.createElement("script");Object.entries(s).forEach(([t,n])=>e.setAttribute(t,n)),document.querySelector("#tw-comment").appendChild(e);const t=document.querySelector("#theme-toggle");t&&t.addEventListener("click",setGiscusTheme);const n=document.querySelector("#theme-toggle-float");n&&n.addEventListener("click",setGiscusTheme)})</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://congyuxiaoyoudao.github.io/>The Only Problem's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>